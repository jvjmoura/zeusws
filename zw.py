import streamlit as st
from pathlib import Path
from openai import OpenAI
import pydub
from moviepy.editor import VideoFileClip
from dotenv import load_dotenv, find_dotenv
import os

_ = load_dotenv(find_dotenv())

PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.mp3'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def transcreve_audio(caminho_audio):
    with open(caminho_audio, 'rb') as arquivo_audio:
        transcricao = client.audio.transcriptions.create(
            model='whisper-1',
            language='pt',
            response_format='text',
            file=arquivo_audio,
        )
        return transcricao

def analisa_transcricao(transcricao):
    prompt = f"""
    Analise cuidadosamente a seguinte transcri√ß√£o e extraia as informa√ß√µes mais relevantes:

    {transcricao}

    Com base apenas nas informa√ß√µes contidas na transcri√ß√£o, crie uma tabela Markdown com as seguintes colunas:
    1. 'Interlocutor': Identifique quem est√° falando, se poss√≠vel. Se n√£o for poss√≠vel identificar especificamente, use "Interlocutor 1", "Interlocutor 2", etc., para diferentes vozes.
    2. 'Conte√∫do': Resuma o conte√∫do apresentado por cada interlocutor, sem fazer ju√≠zos de valor.
    3. 'Detalhes': Inclua quaisquer detalhes ou informa√ß√µes adicionais mencionados.

    Regras adicionais:
    - Se n√£o for poss√≠vel distinguir interlocutores diferentes, use "Narrador" como interlocutor.
    - Se houver uma mudan√ßa clara de t√≥pico ou uma nova informa√ß√£o sendo introduzida, crie uma nova linha na tabela, mesmo que seja o mesmo interlocutor.
    - Foque em apresentar o conte√∫do de forma neutra, sem interpretar ou avaliar as informa√ß√µes.
    - Mantenha cada ponto conciso, mas informativo.
    - Se alguma informa√ß√£o n√£o estiver clara ou n√£o for mencionada, indique como "N√£o especificado".

    Ap√≥s a tabela, adicione um quarto item chamado "Resumo" que deve apresentar, de forma objetiva e sem interpreta√ß√µes:
    - Endere√ßos citados
    - Quando ocorreram os fatos
    - O que aconteceu
    - Hor√°rio, dia e m√™s dos eventos mencionados
    - Um resumo geral dos principais fatos narrados

    Importante: No resumo, n√£o crie nenhuma informa√ß√£o nova. Restrinja-se estritamente ao conte√∫do da transcri√ß√£o. Se alguma dessas informa√ß√µes n√£o estiver presente na transcri√ß√£o, indique como "N√£o mencionado na transcri√ß√£o".
    """

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "Voc√™ √© um assistente especializado em an√°lise de texto, capaz de extrair informa√ß√µes cruciais de transcri√ß√µes."},
            {"role": "user", "content": prompt}
        ]
    )

    return response.choices[0].message.content

def exibe_resultado(transcricao):
    st.subheader("Transcri√ß√£o Original")
    st.write(transcricao)

    st.subheader("An√°lise da Transcri√ß√£o")
    with st.spinner("Analisando a transcri√ß√£o..."):
        analise = analisa_transcricao(transcricao)
    st.markdown(analise)

def _salva_audio_do_video(video_bytes):
    with open(ARQUIVO_VIDEO_TEMP, mode='wb') as video_f:
        video_f.write(video_bytes.read())
    moviepy_video = VideoFileClip(str(ARQUIVO_VIDEO_TEMP))
    moviepy_video.audio.write_audiofile(str(ARQUIVO_AUDIO_TEMP))

def transcreve_tab_video():
    arquivo_video = st.file_uploader('Adicione um arquivo de v√≠deo .mp4', type=['mp4'])
    if arquivo_video is not None:
        with st.spinner("Processando o v√≠deo..."):
            _salva_audio_do_video(arquivo_video)
            transcricao = transcreve_audio(ARQUIVO_AUDIO_TEMP)
        exibe_resultado(transcricao)

def transcreve_tab_audio():
    arquivo_audio = st.file_uploader('Adicione um arquivo de √°udio .mp3', type=['mp3'])
    if arquivo_audio is not None:
        with st.spinner("Transcrevendo o √°udio..."):
            transcricao = client.audio.transcriptions.create(
                model='whisper-1',
                language='pt',
                response_format='text',
                file=arquivo_audio,
            )
        exibe_resultado(transcricao)

def sidebar_info():
    # Logotipo
    logo_url = "https://cdn.midjourney.com/143dff27-3598-4ca6-becb-e6387047a007/0_1.png"  # Substitua pela URL real do seu logotipo
    st.sidebar.image(logo_url, use_column_width=True, caption="Zeus Whisper")

    st.sidebar.title("Como usar o Zeus Whisper")
    st.sidebar.markdown("""
    1. Escolha entre as op√ß√µes 'V√≠deo' ou '√Åudio'.
    2. Fa√ßa upload do seu arquivo de v√≠deo (.mp4) ou √°udio (.mp3).
    3. Aguarde o processamento e a transcri√ß√£o.
    4. Revise a transcri√ß√£o e a an√°lise gerada.
    """)
    
    st.sidebar.info("Lembre-se: A qualidade da transcri√ß√£o depende da clareza do √°udio original.")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Informa√ß√µes sobre o Projeto")
    st.sidebar.markdown("**Status:** Em constru√ß√£o")
    st.sidebar.markdown("**Desenvolvedor:** Jo√£o Val√©rio")
    st.sidebar.markdown("**Cargo:** Juiz do TJPA")
    st.sidebar.markdown("Esta programa√ß√£o Python est√° atualmente em desenvolvimento.")

def main():
    st.set_page_config(page_title="Zeus Whisper", layout="wide")
    
    sidebar_info()
    
    st.title('Zeus Whisper üéôÔ∏è')
    st.markdown('#### Transcreva e analise √°udio de v√≠deos e arquivos de √°udio')
    
    tab_video, tab_audio = st.tabs(['V√≠deo', '√Åudio'])
    
    with tab_video:
        st.header("Transcri√ß√£o de V√≠deo")
        transcreve_tab_video()
    
    with tab_audio:
        st.header("Transcri√ß√£o de √Åudio")
        transcreve_tab_audio()

if __name__ == '__main__':
    main()
