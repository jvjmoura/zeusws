import streamlit as st
from pathlib import Path
from openai import OpenAI
import pydub
from moviepy.editor import VideoFileClip
from dotenv import load_dotenv, find_dotenv
import os

_ = load_dotenv(find_dotenv())

PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.mp3'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def transcreve_audio(caminho_audio):
    with open(caminho_audio, 'rb') as arquivo_audio:
        transcricao = client.audio.transcriptions.create(
            model='whisper-1',
            language='pt',
            response_format='text',
            file=arquivo_audio,
        )
        return transcricao

def analisa_transcricao(transcricao):
    prompt = f"""
    Com base nas informa√ß√µes contidas na seguinte transcri√ß√£o, crie uma tabela Markdown com as seguintes colunas:

    1. 'Tipo de √Åudio': Identifique o tipo geral de √°udio (ex: entrevista, palestra, conversa informal, etc.).
    2. 'Interlocutor': Identifique quem est√° falando, se poss√≠vel. Se n√£o for poss√≠vel identificar especificamente, use "Interlocutor 1", "Interlocutor 2", etc., para diferentes vozes.
    3. 'Conte√∫do': Resuma o conte√∫do apresentado por cada interlocutor, sem fazer ju√≠zos de valor. Priorize informa√ß√µes como datas, nomes e eventos principais.
    4. 'Detalhes': Inclua quaisquer detalhes ou informa√ß√µes adicionais mencionados.
    5. 'Contexto/Tom': Capture o clima geral da conversa ou emo√ß√µes expressas.
    6. 'Elementos n√£o-verbais': Note pausas significativas, interrup√ß√µes, sobreposi√ß√µes de fala ou outros elementos relevantes.
    7. 'Observa√ß√µes': Anote ambiguidades, contradi√ß√µes, ou informa√ß√µes que precisem de esclarecimento.

    Regras adicionais:
    - Se n√£o for poss√≠vel distinguir interlocutores diferentes, use "Narrador" como interlocutor.
    - Se houver uma mudan√ßa clara de t√≥pico ou uma nova informa√ß√£o sendo introduzida, crie uma nova linha na tabela, mesmo que seja o mesmo interlocutor.
    - Foque em apresentar o conte√∫do de forma neutra, sem interpretar ou avaliar as informa√ß√µes.
    - Mantenha cada ponto conciso, mas informativo.
    - Se alguma informa√ß√£o n√£o estiver clara ou n√£o for mencionada, indique como "N√£o especificado".
    - Para transcri√ß√µes longas, foque nas informa√ß√µes mais relevantes e significativas.
    - Consolide informa√ß√µes repetidas, mencionando a frequ√™ncia da repeti√ß√£o se relevante.
    - Destaque e explique brevemente termos t√©cnicos ou jarg√µes espec√≠ficos.
    - Marque informa√ß√µes potencialmente sens√≠veis ou confidenciais, resumindo-as de forma √©tica.

    Ap√≥s a tabela, adicione uma se√ß√£o "Resumo" que deve apresentar, de forma objetiva e sem interpreta√ß√µes:
    - Tipo e dura√ß√£o aproximada do √°udio
    - Endere√ßos citados
    - Quando ocorreram os fatos
    - O que aconteceu
    - Hor√°rio, dia e m√™s dos eventos mencionados
    - Um resumo geral dos principais fatos narrados
    - Quaisquer termos t√©cnicos ou jarg√µes frequentes, com breves explica√ß√µes

    Importante: 
    - No resumo, n√£o crie nenhuma informa√ß√£o nova. Restrinja-se estritamente ao conte√∫do da transcri√ß√£o. 
    - Se alguma dessas informa√ß√µes n√£o estiver presente na transcri√ß√£o, indique como "N√£o mencionado na transcri√ß√£o".
    - Adapte a extens√£o e o n√≠vel de detalhe do resumo de acordo com a dura√ß√£o do √°udio.
    - Se houver informa√ß√µes contradit√≥rias ou amb√≠guas, mencione-as claramente no resumo.

    Transcri√ß√£o:
    {transcricao}
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Voc√™ √© um assistente especializado em analisar e resumir transcri√ß√µes de √°udio de forma detalhada e estruturada."},
            {"role": "user", "content": prompt}
        ]
    )

    return response.choices[0].message.content

def exibe_resultado(transcricao):
    st.subheader("Transcri√ß√£o Original")
    st.write(transcricao)

    st.subheader("An√°lise Detalhada da Transcri√ß√£o")
    with st.spinner("Analisando a transcri√ß√£o..."):
        analise = analisa_transcricao(transcricao)
    st.markdown(analise)

def _salva_audio_do_video(video_bytes):
    with open(ARQUIVO_VIDEO_TEMP, mode='wb') as video_f:
        video_f.write(video_bytes.read())
    moviepy_video = VideoFileClip(str(ARQUIVO_VIDEO_TEMP))
    moviepy_video.audio.write_audiofile(str(ARQUIVO_AUDIO_TEMP))

def transcreve_tab_video():
    arquivo_video = st.file_uploader('Adicione um arquivo de v√≠deo .mp4', type=['mp4'])
    if arquivo_video is not None:
        with st.spinner("Processando o v√≠deo..."):
            _salva_audio_do_video(arquivo_video)
            transcricao = transcreve_audio(ARQUIVO_AUDIO_TEMP)
        exibe_resultado(transcricao)

def transcreve_tab_audio():
    arquivo_audio = st.file_uploader('Adicione um arquivo de √°udio .mp3 ou .m4a', type=['mp3', 'm4a'])
    if arquivo_audio is not None:
        with st.spinner("Transcrevendo o √°udio..."):
            if arquivo_audio.type == 'audio/m4a':
                # Converter M4A para MP3
                audio = pydub.AudioSegment.from_file(arquivo_audio, format="m4a")
                audio.export(ARQUIVO_AUDIO_TEMP, format="mp3")
                arquivo_para_transcricao = ARQUIVO_AUDIO_TEMP
            else:
                arquivo_para_transcricao = arquivo_audio

            transcricao = client.audio.transcriptions.create(
                model='whisper-1',
                language='pt',
                response_format='text',
                file=arquivo_para_transcricao,
            )
        exibe_resultado(transcricao)

def sidebar_info():
    # Logotipo
    logo_url = "https://cdn.midjourney.com/143dff27-3598-4ca6-becb-e6387047a007/0_1.png"  # Substitua pela URL real do seu logotipo
    st.sidebar.image(logo_url, use_column_width=True, caption="Zeus Whisper")

    st.sidebar.title("Como usar o Zeus Whisper")
    st.sidebar.markdown("""
    1. Escolha entre as op√ß√µes 'V√≠deo' ou '√Åudio'.
    2. Fa√ßa upload do seu arquivo de v√≠deo (.mp4) ou √°udio (.mp3 ou .m4a).
    3. Aguarde o processamento e a transcri√ß√£o.
    4. Revise a transcri√ß√£o e a an√°lise detalhada gerada.
    """)
    
    st.sidebar.info("Lembre-se: A qualidade da transcri√ß√£o depende da clareza do √°udio original.")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Informa√ß√µes sobre o Projeto")
    st.sidebar.markdown("**Status:** Em constru√ß√£o")
    st.sidebar.markdown("**Desenvolvedor:** Jo√£o Val√©rio")
    st.sidebar.markdown("**Cargo:** Juiz do TJPA")
    st.sidebar.markdown("Esta programa√ß√£o Python est√° atualmente em desenvolvimento.")

def main():
    st.set_page_config(page_title="Zeus Whisper", layout="wide")
    
    sidebar_info()
    
    st.title('Zeus Whisper üéôÔ∏è')
    st.markdown('#### Transcreva e analise √°udio de v√≠deos e arquivos de √°udio')
    
    tab_video, tab_audio = st.tabs(['V√≠deo', '√Åudio'])
    
    with tab_video:
        st.header("Transcri√ß√£o de V√≠deo")
        transcreve_tab_video()
    
    with tab_audio:
        st.header("Transcri√ß√£o de √Åudio")
        transcreve_tab_audio()

if __name__ == '__main__':
    main()